---
layout: post
title: CNN结构演化
category: DL
comments: true
---

#### 演化脉络

![cnnyh](https://raw.githubusercontent.com/glbing/blogs/gh-pages/images/cnnyh.png)

上图所示是CNN结构演化的历史，起点是神经认知机模型，已经出现了卷积结构，但是第一个CNN模型诞生于1989年，1998年诞生了LeNet。随着ReLU和dropout的提出，以及GPU和大数据带来的历史机遇，CNN在12年迎来了历史突破。12年之后，CNN的演化路径可以总结为四条：**1）更深的网络，2）增强卷积模的功能以及上诉两种思路的融合，3）从分类到检测，4）增加新的功能模块。**

##### 早期尝试

![lenet](https://raw.githubusercontent.com/glbing/blogs/gh-pages/images/lenet.png)  

1998年，LeCun提出LeNet，并成功应用于美国手写数字识别。但很快，CNN的锋芒被SVM和手工设计的局部特征盖过。

##### 历史突破
![alexnet](https://raw.githubusercontent.com/glbing/blogs/gh-pages/images/alexnet.png)  

历史的转折在2012年到来，AlexNet, 在当年的ImageNet图像分类竞赛中，top-5错误率比上一年的冠军下降了十个百分点。AlexNet的成功既得益研究者的自我奋斗：Relu和Dropout的提出, 也是大历史进程的结果：大数据训练和GPU并行计算。
2012年之后，CNN朝着不同方向演化。

##### 第一条演化路径：网络变深

代表性的2014-VGG-NET，[prototxt](http://cs.stanford.edu/people/karpathy/vgg_train_val.prototxt) [论文](http://arxiv.org/pdf/1409.1556v6.pdf)


[..](https://mp.weixin.qq.com/s?__biz=MzI1NTE4NTUwOQ==&mid=502840969&idx=1&sn=05b8d27dccf6efc3f85f47a74669e1c9&scene=1&srcid=05071TYA23a6ajlHsVV3594N&pass_ticket=ADe2fxqUaaryDDryU%2BLtiOaInmHW4ivu6HaESK%2FUJYjRTl38xL6bhK%2Fbyd925IRd#rd)
