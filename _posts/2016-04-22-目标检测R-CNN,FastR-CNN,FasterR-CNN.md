---
layout: post
title: 目标检测R-CNN,Fast R-CNN,Faster R-CNN
category: DL
comments: true
---

##### RNN 系列

bounding box:(x,y,h,w),为box的高和宽  
在2013年底，深度学习给目标检测任务点起了一把火，这个火种就是R-CNN，其中R对应于“Region(区域)”，意指CNN以图像区域作为输入，这个工作最终发展成了一个系列，也启发和衍生出了大量的后续工作，这一场大火简直烧红了计算机视觉领域的半边天。


R-CNN的提出变革了目标检测方法中很多旧有的做法，同时在标准的目标检测评测数据集上使检测精度得到了前所未有的提升。在检测方法上的变革，首当其冲的是抛弃了滑动窗口范式，取而代之的是一个新的生成候选窗口的环节。对于给定的图像，不再用一个滑动窗口去对图像进行扫描，枚举所有可能的情况，而是采用某种方式“提名”出一些候选窗口，在获得对待检测目标可接受的召回率的前提下，候选窗口的数量可以控制在几千个或者几百个。从某种意义上讲，VJ 人脸检测器中多个分类器相级联，每一级分类器都在为接下来的一级分类器提名候选窗口，但是这和 R-CNN 所采用的生成候选窗口的方式有一个重要的区别：实际上所有的窗口仍然都被检查了一遍，只是不断在排除，这是一种减法式的方案。相比之下，R-CNN 采用的候选窗口生成方式，是根据图像的某些特征来猜测可能有哪些地方存在待检测的目标，以及这些目标有多大，这是一种从无到有的加法式的方案。Selective Search是一种典型的候选窗口生成方法，其采用了图像分割的思路，简单地说，Selective Search方法先基于各种颜色特征将图像划分为多个小块，然后自底向上地对不同的块进行合并，在这个过程中，合并前后的每一个块都对应于一个候选窗口，最后挑出最有可能包含待检测目标的窗口作为候选窗口。


除了引入候选窗口生成方法，第二点非常大的改变在特征提取上：不再采用人工设计的特征，而是用 CNN来自动学习特征。特征提取过程就是从原始的输入图像（像素颜色值构成的矩阵）变换到特征向量的过程，之前的如 Haar 特征等是科研工作者根据自己的经验和对研究对象的认识设计出来的，换言之人工定义了一个变换，而新的做法是只限定这个变换能够用CNN来表示——事实上 CNN 已经可以表示足够多足够复杂的变换,而不具体设计特征提取的细节，用训练数据来取代人的角色。这种自动学习特征的做法是深度学习一个非常鲜明的特色。自动去学习合适的特征,这种做法的好处和让分类器自动去学习自己的参数的好处是类似的，不仅避免了人工干预，解放了人力，而且有利于学习到更契合实际数据和目标的特征来，特征提取和分类两个环节可以相互促进，相辅相成；不过缺点也是有的，自动学习出的特征往往可解释性比较差，不能让人直观地去理解为什么这样提取出特征会更好，另外就是对训练集会产生一定程度的依赖。


还有一点值得一提的是，R-CNN在检测过程中引入了一个新的环节：边框回归，检测不再仅仅是一个分类问题，它还是一个回归问题——回归和分类的区别就在于回归模型输出的不是离散的类别标签，而是连续的实数值。边框回归指的是在给定窗口的基础上去预测真实检测框的位置和大小，也就是说，有了候选窗口之后，如果其被判别成了一个人脸窗口，那就会进一步被调整以得到更加精确的位置和大小——和待检测目标贴合得更好。边框回归一方面提供了一个新的角度来定义检测任务，另一方面对于提高检测结果的精确度有比较显著的作用。


用R-CNN进行目标检测的流程是：先采用如 Selective Search等方法生成候选窗口，然后用学习好的CNN提取候选窗口对应的特征，接着训练分类器基于提取的特征对候选窗口进行分类，最后对判别为人脸的窗口采用边框回归进行修正。


##### Fast RNN 系列

虽然R-CNN带来了目标检测精度的一次巨大提升，然而由于所采用的候选窗口生成方法和深度网络都具有比较高的计算复杂度，因而检测速度非常慢。为了解决R-CNN的速度问题,紧接着出现了Fast R-CNN和Faster R-CNN，从名字上可以看到,它们的速度一个比一个快。第一步加速是采用了类似于 VJ 人脸检测器中积分图的策略,积分图是对应整张输入图像计算的，它就像一张表,在提取单个窗口的特征时，直接通过查表来获取所需要的数据，然后进行简单的计算即可，在R-CNN中每个候选窗口都需要单独通过CNN来提取特征，当两个窗口之间有重叠部分时，重叠部分实际上被重复计算了两次，而在 Fast R-CNN 中，直接以整张图像作为输入，先得到整张图对应的卷积特征图，然后对于每一个候选窗口，在提取特征时直接去整张图对应的卷积特征图上取出窗口对应的区域，从而避免重复计算，之后只需要通过所谓的RoIPooling层来将所有的区域放缩到相同大小即可，这一策略的使用可以提供几十甚至上百倍的加速。第二步加速，Fast R-CNN利用了一种名为 SVD 的矩阵分解技术，其作用是将一个大的矩阵(近似)拆解为三个小的矩阵的乘积，使得拆解之后三个矩阵的元素数目远小于原来大矩阵的元素数目，从而达到在计算矩阵乘法时降低计算量的目的，通过将 SVD应用于全连接层的权值矩阵，处理一张图片所需要的时间能够降低30%。

##### Faster RNN 系列

Faster R-CNN开始着眼于生成候选窗口的环节，其采用 CNN 来生成候选窗口，同时让其和分类、边框回归所使用的 CNN 共享卷积层，这样使得两个步骤中可以使用同样的卷积特征图，从而极大地减少计算量。


![技术员..](https://raw.githubusercontent.com/glbing/blogs/gh-pages/images/11.png)




除了采用各种策略进行加速，从R-CNN到Faster R-CNN，检测的框架和网络结构也在不断发生改变。R-CNN从整体框架上来说，和传统的检测方法没有本质区别，不同的环节由单独的模块来完成：一个模块生成候选窗口（Selective Search），一个模块进行特征提取（CNN），一个模块对窗口进行分类（SVM），除此之外还增加了一个模块做边框回归。到Fast R-CNN的时候，后面三个模块合并成了一个模块，全部都用CNN来完成,因此整个系统实际上只剩下两个模块：一个模块生成候选窗口，另一个模块直接对窗口进行分类和修正。再到Faster R-CNN，所有的模块都整合到了一个CNN中来完成，形成了一种端到端(end-to-end)的框架：直接从输入图像通过一个模型得到最终的检测结果，这种多任务在同一个模型中共同学习的做法，能够有效利用任务之间的相关性，达到相辅相成、相得益彰的效果。从 R-CNN 到 Faster R-CNN，这是一个化零为整的过程，其之所以能够成功，一方面得益于CNN强大的非线性建模能力，能够学习出契合各种不同子任务的特征，另一方面也是因为人们认识和思考检测问题的角度在不断发生改变，打破旧有滑动窗口的框架，将检测看成一个回归问题，不同任务之间的耦合。尽管目前 Faster R-CNN在速度上仍然无法和采用非深度学习方法的检测器相比,但是随着硬件计算能力的不断提升和新的CNN加速策略的接连出现，速度问题在不久的将来一定能够得到解决。


##### 全卷积网络和DenseBox

卷积层是CNN区别于其它类型神经网络的本质特点，不过CNN通常也不仅仅只包含卷积层，其也会包含全连接层，全连接层的坏处就在于其会破坏图像的空间结构，因此人们便开始用卷积层来“替代”全连接层，通常采用1 × 1的卷积核，这种不包含全连接层的CNN称为全卷积网络（FCN）。FCN最初是用于图像分割任务，之后开始在计算机视觉领域的各种问题上得到应用，事实上，Faster R-CNN中用来生成候选窗口的CNN就是一个FCN。

FCN 的特点就在于输入和输出都是二维的图像，并且输出和输入具有相对应的空间结构，在这种情况下，我们可以将 FCN 的输出看成是一张热度图，用热度来指示待检测目标的位置和覆盖的区域：在目标所处的区域内显示较高的热度，而在背景区域显示较低的热度，这也可以看成是对图像上的每一个像素点都进行了分类：这个点是否位于待检测的目标上。DenseBox是一个典型的基于全卷积网络的目标检测器，其通过 FCN得到待检测目标的热度图，然后根据热度图来获得目标的位置和大小，如下。这给目标检测又提供了一种新的问题解决思路。

![技术员..](https://raw.githubusercontent.com/glbing/blogs/gh-pages/images/12.png)

在DenseBox中，还有一点值得一提，其在分类的同时还会预测特征点的位置——就像上篇中提到的 JointCascade一样，DenseBox将检测和特征点定位两个任务集成在同一个网络中，并且也用热图的方式来确定每个点的位置。
